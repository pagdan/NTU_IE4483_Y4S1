{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee64dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\503007766.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  DATA_ROOT = Path(\"D:\\ie4483 dataset\\datasets\")  # <-- CHANGE ME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'img_h': 150,\n",
       " 'img_w': 150,\n",
       " 'batch_size': 32,\n",
       " 'epochs': 30,\n",
       " 'lr': 0.0003,\n",
       " 'weight_decay': 0.0001,\n",
       " 'num_workers': 4,\n",
       " 'train_limit_per_class': None,\n",
       " 'val_limit_per_class': None,\n",
       " 'save_dir': 'checkpoints',\n",
       " 'model_name': 'alexnet_150.pt'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"D:\\ie4483 dataset\\datasets\")  \n",
    "TRAIN_DIR = DATA_ROOT / \"train\"\n",
    "VAL_DIR   = DATA_ROOT / \"val\"\n",
    "TEST_DIR  = DATA_ROOT / \"test\"\n",
    "\n",
    "CFG = {\n",
    "    \"img_h\": 150,\n",
    "    \"img_w\": 150,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 30,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_workers\": 4,\n",
    "    \"train_limit_per_class\": None,  \n",
    "    \"val_limit_per_class\":   None,  \n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"model_name\": \"alexnet_150.pt\",\n",
    "}\n",
    "os.makedirs(CFG[\"save_dir\"], exist_ok=True)\n",
    "CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e522dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (CFG[\"img_h\"], CFG[\"img_w\"])\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(img_size, antialias=True),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=40,\n",
    "        translate=(0.2, 0.2),\n",
    "        scale=(0.8, 1.2),\n",
    "        shear=0.2\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # matches Keras horizontal_flip=True\n",
    "    transforms.ToTensor(),  # rescales to [0,1]\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(img_size, antialias=True),\n",
    "    transforms.ToTensor(),  # rescales to [0,1], no aug\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35edfd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog'] {'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(VAL_DIR,   transform=val_tfms)\n",
    "print(train_ds.classes, train_ds.class_to_idx)  # expect ['cat','dog'] and {'cat':0,'dog':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae35dfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cap_per_class_indices(dataset, limit_per_class=None):\n",
    "    if limit_per_class is None:\n",
    "        return np.arange(len(dataset))\n",
    "    targets = [dataset.samples[i][1] for i in range(len(dataset))]\n",
    "    idx_by_class = {c: [] for c in set(targets)}\n",
    "    for i, t in enumerate(targets):\n",
    "        if len(idx_by_class[t]) < limit_per_class:\n",
    "            idx_by_class[t].append(i)\n",
    "    capped = np.concatenate([idx_by_class[c] for c in sorted(idx_by_class.keys())])\n",
    "    return capped\n",
    "\n",
    "CFG[\"train_limit_per_class\"] = 5000\n",
    "CFG[\"val_limit_per_class\"]   = 1250\n",
    "\n",
    "\n",
    "train_indices = cap_per_class_indices(train_ds, CFG[\"train_limit_per_class\"])\n",
    "val_indices   = cap_per_class_indices(val_ds,   CFG[\"val_limit_per_class\"])\n",
    "\n",
    "train_ds_cap = Subset(train_ds, train_indices)\n",
    "val_ds_cap   = Subset(val_ds,   val_indices)\n",
    "len(train_ds_cap), len(val_ds_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde18b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds_cap, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
    "    num_workers=CFG[\"num_workers\"], pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds_cap, batch_size=CFG[\"batch_size\"], shuffle=False,\n",
    "    num_workers=CFG[\"num_workers\"], pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847d9484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\1932791875.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.012034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "in_features = model.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs\"])\n",
    "scaler = GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "sum(p.numel() for p in model.parameters())/1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1983d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train 0.4737/0.7742 | Val 0.2873/0.8652 | lr 2.99e-04 | 134.2s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.8652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train 0.3269/0.8591 | Val 0.2542/0.9028 | lr 2.97e-04 | 134.0s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train 0.3044/0.8670 | Val 0.2281/0.9088 | lr 2.93e-04 | 134.1s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9088)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train 0.2752/0.8846 | Val 0.2891/0.9020 | lr 2.87e-04 | 135.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train 0.2485/0.8901 | Val 0.2335/0.9184 | lr 2.80e-04 | 135.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train 0.2405/0.9012 | Val 0.1994/0.9164 | lr 2.71e-04 | 136.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train 0.2268/0.9079 | Val 0.1760/0.9300 | lr 2.61e-04 | 135.7s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train 0.2097/0.9142 | Val 0.1616/0.9404 | lr 2.50e-04 | 136.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train 0.2041/0.9192 | Val 0.1576/0.9336 | lr 2.38e-04 | 136.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train 0.1948/0.9227 | Val 0.1465/0.9412 | lr 2.25e-04 | 135.8s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9412)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train 0.1920/0.9218 | Val 0.1413/0.9408 | lr 2.11e-04 | 135.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train 0.1799/0.9257 | Val 0.1573/0.9372 | lr 1.96e-04 | 136.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train 0.1679/0.9336 | Val 0.1493/0.9392 | lr 1.81e-04 | 139.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train 0.1570/0.9389 | Val 0.1629/0.9388 | lr 1.66e-04 | 137.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train 0.1429/0.9424 | Val 0.1627/0.9420 | lr 1.50e-04 | 138.2s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train 0.1388/0.9414 | Val 0.1574/0.9404 | lr 1.34e-04 | 137.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train 0.1224/0.9512 | Val 0.1607/0.9428 | lr 1.19e-04 | 137.6s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9428)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train 0.1237/0.9509 | Val 0.1679/0.9360 | lr 1.04e-04 | 141.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train 0.1134/0.9526 | Val 0.1427/0.9456 | lr 8.90e-05 | 141.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train 0.1010/0.9583 | Val 0.1638/0.9428 | lr 7.50e-05 | 142.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train 0.0906/0.9656 | Val 0.1705/0.9468 | lr 6.18e-05 | 142.2s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9468)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train 0.0926/0.9636 | Val 0.1541/0.9532 | lr 4.96e-05 | 139.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train 0.0810/0.9687 | Val 0.1777/0.9520 | lr 3.85e-05 | 139.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train 0.0711/0.9720 | Val 0.1806/0.9508 | lr 2.86e-05 | 138.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train 0.0702/0.9735 | Val 0.1718/0.9536 | lr 2.01e-05 | 140.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train 0.0641/0.9752 | Val 0.1800/0.9520 | lr 1.30e-05 | 137.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train 0.0596/0.9779 | Val 0.1795/0.9544 | lr 7.34e-06 | 138.0s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train 0.0610/0.9782 | Val 0.1785/0.9560 | lr 3.28e-06 | 137.4s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_150.pt (val_acc=0.9560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train 0.0570/0.9779 | Val 0.1816/0.9556 | lr 8.22e-07 | 137.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train 0.0556/0.9779 | Val 0.1808/0.9560 | lr 0.00e+00 | 139.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.473652</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.287269</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>2.991783e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.326903</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.254204</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>2.967221e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.304356</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>2.926585e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.275173</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.289079</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>2.870318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.248456</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>2.799038e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.240493</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.199413</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>2.713525e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.226812</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.176040</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>2.614717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.209659</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.161583</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>2.503696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.204092</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.157629</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>2.381678e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.194782</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.146496</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>2.250000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.191965</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.141281</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>2.110105e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.179879</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>1.963525e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.167877</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>0.149295</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>1.811868e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.156978</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.162879</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>1.656793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>1.500000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.138784</td>\n",
       "      <td>0.9414</td>\n",
       "      <td>0.157378</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>1.343207e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.122386</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.160699</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>1.188132e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.167935</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>1.036475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.142741</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>8.898950e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.163803</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>7.500000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.090573</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.170499</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>6.183221e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.092572</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.154077</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>4.963041e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.081019</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>3.852828e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.071122</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.180560</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>2.864745e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.070178</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.171796</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>2.009619e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.179986</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>1.296818e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.059636</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.179474</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>7.341523e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.060989</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.178515</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>3.277860e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.057017</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.181579</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>8.217157e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.055615</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.180802</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_acc  val_loss  val_acc            lr\n",
       "0       1    0.473652     0.7742  0.287269   0.8652  2.991783e-04\n",
       "1       2    0.326903     0.8591  0.254204   0.9028  2.967221e-04\n",
       "2       3    0.304356     0.8670  0.228077   0.9088  2.926585e-04\n",
       "3       4    0.275173     0.8846  0.289079   0.9020  2.870318e-04\n",
       "4       5    0.248456     0.8901  0.233533   0.9184  2.799038e-04\n",
       "5       6    0.240493     0.9012  0.199413   0.9164  2.713525e-04\n",
       "6       7    0.226812     0.9079  0.176040   0.9300  2.614717e-04\n",
       "7       8    0.209659     0.9142  0.161583   0.9404  2.503696e-04\n",
       "8       9    0.204092     0.9192  0.157629   0.9336  2.381678e-04\n",
       "9      10    0.194782     0.9227  0.146496   0.9412  2.250000e-04\n",
       "10     11    0.191965     0.9218  0.141281   0.9408  2.110105e-04\n",
       "11     12    0.179879     0.9257  0.157324   0.9372  1.963525e-04\n",
       "12     13    0.167877     0.9336  0.149295   0.9392  1.811868e-04\n",
       "13     14    0.156978     0.9389  0.162879   0.9388  1.656793e-04\n",
       "14     15    0.142880     0.9424  0.162741   0.9420  1.500000e-04\n",
       "15     16    0.138784     0.9414  0.157378   0.9404  1.343207e-04\n",
       "16     17    0.122386     0.9512  0.160699   0.9428  1.188132e-04\n",
       "17     18    0.123737     0.9509  0.167935   0.9360  1.036475e-04\n",
       "18     19    0.113430     0.9526  0.142741   0.9456  8.898950e-05\n",
       "19     20    0.100953     0.9583  0.163803   0.9428  7.500000e-05\n",
       "20     21    0.090573     0.9656  0.170499   0.9468  6.183221e-05\n",
       "21     22    0.092572     0.9636  0.154077   0.9532  4.963041e-05\n",
       "22     23    0.081019     0.9687  0.177700   0.9520  3.852828e-05\n",
       "23     24    0.071122     0.9720  0.180560   0.9508  2.864745e-05\n",
       "24     25    0.070178     0.9735  0.171796   0.9536  2.009619e-05\n",
       "25     26    0.064102     0.9752  0.179986   0.9520  1.296818e-05\n",
       "26     27    0.059636     0.9779  0.179474   0.9544  7.341523e-06\n",
       "27     28    0.060989     0.9782  0.178515   0.9560  3.277860e-06\n",
       "28     29    0.057017     0.9779  0.181579   0.9556  8.217157e-07\n",
       "29     30    0.055615     0.9779  0.180802   0.9560  0.000000e+00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_epoch(loader, model, optimizer=None, scaler=None):\n",
    "    is_train = optimizer is not None\n",
    "    if is_train: model.train()\n",
    "    else: model.eval()\n",
    "\n",
    "    total_loss, all_preds, all_tgts = 0.0, [], []\n",
    "    for imgs, tgts in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        tgts = tgts.to(device, non_blocking=True)\n",
    "\n",
    "        with autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, tgts)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_tgts.append(tgts.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds); all_tgts = np.concatenate(all_tgts)\n",
    "    acc = accuracy_score(all_tgts, all_preds)\n",
    "    return avg_loss, acc, all_preds, all_tgts\n",
    "\n",
    "best_acc, best_path = 0.0, os.path.join(CFG[\"save_dir\"], CFG[\"model_name\"])\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, CFG[\"epochs\"]+1):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc, _, _ = run_epoch(train_loader, model, optimizer, scaler)\n",
    "    val_loss, val_acc, vp, vt = run_epoch(val_loader, model, None, None)\n",
    "    scheduler.step()\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss, \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss, \"val_acc\": val_acc,\n",
    "        \"lr\": scheduler.get_last_lr()[0]\n",
    "    })\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train {train_loss:.4f}/{train_acc:.4f} | \"\n",
    "          f\"Val {val_loss:.4f}/{val_acc:.4f} | \"\n",
    "          f\"lr {scheduler.get_last_lr()[0]:.2e} | \"\n",
    "          f\"{time.time()-t0:.1f}s\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"class_to_idx\": train_ds.class_to_idx,\n",
    "            \"cfg\": CFG\n",
    "        }, best_path)\n",
    "        print(f\"  ✔ Saved new best to {best_path} (val_acc={best_acc:.4f})\")\n",
    "\n",
    "pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ebaeb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\2411271896.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.96      0.96      0.96      1250\n",
      "         dog       0.96      0.96      0.96      1250\n",
      "\n",
      "    accuracy                           0.96      2500\n",
      "   macro avg       0.96      0.96      0.96      2500\n",
      "weighted avg       0.96      0.96      0.96      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1194,   56],\n",
       "       [  54, 1196]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "_, _, preds, tgts = run_epoch(val_loader, model, None, None)\n",
    "print(\"Val accuracy:\", accuracy_score(tgts, preds))\n",
    "print(classification_report(tgts, preds, target_names=train_ds.classes))\n",
    "\n",
    "cm = confusion_matrix(tgts, preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc980d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images found: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_424\\375779877.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(device.type==\"cuda\")):\n",
      "100%|██████████| 16/16 [00:09<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission.csv with 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# rebuild the test DataLoader with 0 workers to avoid Windows multiprocessing issues\n",
    "test_ds = TestImageFolder(TEST_DIR, val_tfms)\n",
    "print(\"Test images found:\", len(test_ds))\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=CFG[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,               # <— key change\n",
    "    pin_memory=False,            \n",
    "    persistent_workers=False     # ensure workers aren't kept alive\n",
    ")\n",
    "\n",
    "# re-run inference\n",
    "all_ids, all_preds = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, paths in tqdm(test_dl):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        with autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "        pred_idx = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "        all_preds.extend(pred_idx.tolist())\n",
    "        all_ids.extend([Path(p).stem for p in paths])\n",
    "\n",
    "sub_df = pd.DataFrame({\"ID\": all_ids, \"label\": all_preds})\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Wrote submission.csv with\", len(sub_df), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b91d676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\chuan\\AppData\\Local\\Programs\\Microsoft VS Code\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Exists?\", os.path.exists(\"submission.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a9e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: D:\\ie4483 dataset\\datasets\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "out_csv = DATA_ROOT / \"submission.csv\"\n",
    "sub_df.to_csv(str(out_csv), index=False)  # str() for Windows paths\n",
    "print(\"Saved to:\", out_csv.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce21b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_size': 224, 'batch_size': 128, 'epochs': 30, 'lr': 0.001, 'weight_decay': 0.0001, 'num_workers': 2, 'save_dir': 'checkpoints', 'model_name': 'alexnet_cifar10.pt', 'use_mixup': False, 'mixup_alpha': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# ---- CIFAR-10 configuration ----\n",
    "CIFAR = {\n",
    "    \"img_size\": 224,        # upscale 32x32 -> 224x224 to leverage ImageNet-pretrained AlexNet\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 30,           # typical for CIFAR-10\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_workers\": 2,       # set to 0 on Windows if workers crash\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"model_name\": \"alexnet_cifar10.pt\",\n",
    "    \"use_mixup\": False,     # optional regularization\n",
    "    \"mixup_alpha\": 0.2\n",
    "}\n",
    "import os\n",
    "os.makedirs(CIFAR[\"save_dir\"], exist_ok=True)\n",
    "print(CIFAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebb84b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tfms_c10 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Resize((CIFAR[\"img_size\"], CIFAR[\"img_size\"]), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "test_tfms_c10 = transforms.Compose([\n",
    "    transforms.Resize((CIFAR[\"img_size\"], CIFAR[\"img_size\"]), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Download & build datasets\n",
    "cifar10_train = datasets.CIFAR10(root=\"./data\", train=True,  download=True, transform=train_tfms_c10)\n",
    "cifar10_test  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_tfms_c10)\n",
    "\n",
    "cifar10_classes = cifar10_train.classes\n",
    "print(\"CIFAR-10 classes:\", cifar10_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b85ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (small) size: 20000\n",
      "Test  (small) size: 4000\n"
     ]
    }
   ],
   "source": [
    "# === Cell C (REPLACEMENT): DataLoaders for CIFAR-10 with 10k train / 2k test ===\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "# Reproducible stratified sampling: 1,000 per class for train, 200 per class for test\n",
    "train_per_class = 2000\n",
    "test_per_class  = 400\n",
    "num_classes = 10\n",
    "rng = np.random.default_rng(42)  # keep consistent with your notebook seed\n",
    "\n",
    "def stratified_indices(dataset, per_class):\n",
    "    # torchvision CIFAR10 stores numeric labels in dataset.targets (list[int])\n",
    "    targets = np.array(dataset.targets)\n",
    "    indices = []\n",
    "    for c in range(num_classes):\n",
    "        cls_idx = np.where(targets == c)[0]\n",
    "        pick = rng.choice(cls_idx, size=per_class, replace=False)\n",
    "        indices.append(pick)\n",
    "    return np.concatenate(indices)\n",
    "\n",
    "train_idx_small = stratified_indices(cifar10_train, train_per_class)  # 10 * 1000 = 20,000\n",
    "test_idx_small  = stratified_indices(cifar10_test,  test_per_class)   # 10 * 200  = 4,000\n",
    "\n",
    "cifar10_train_small = Subset(cifar10_train, train_idx_small)\n",
    "cifar10_test_small  = Subset(cifar10_test,  test_idx_small)\n",
    "\n",
    "print(\"Train (small) size:\", len(cifar10_train_small))  # -> 10000\n",
    "print(\"Test  (small) size:\", len(cifar10_test_small))   # -> 2000\n",
    "\n",
    "# DataLoaders (set num_workers=0 on Windows if you hit worker crashes)\n",
    "train_loader_c10 = DataLoader(\n",
    "    cifar10_train_small,\n",
    "    batch_size=CIFAR[\"batch_size\"],\n",
    "    shuffle=True,                       # stratified subset already; still shuffle batches\n",
    "    num_workers=CIFAR[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader_c10 = DataLoader(\n",
    "    cifar10_test_small,\n",
    "    batch_size=CIFAR[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=CIFAR[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d496376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\1648613737.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_c10 = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.04481"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "alexnet_c10 = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "# replace final Linear (4096 -> 1000) with (4096 -> 10)\n",
    "in_features = alexnet_c10.classifier[-1].in_features\n",
    "alexnet_c10.classifier[-1] = nn.Linear(in_features, 10)\n",
    "alexnet_c10 = alexnet_c10.to(device)\n",
    "\n",
    "criterion_c10 = nn.CrossEntropyLoss()\n",
    "optimizer_c10 = torch.optim.AdamW(alexnet_c10.parameters(), lr=CIFAR[\"lr\"], weight_decay=CIFAR[\"weight_decay\"])\n",
    "scheduler_c10 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_c10, T_max=CIFAR[\"epochs\"])\n",
    "scaler_c10 = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "sum(p.numel() for p in alexnet_c10.parameters())/1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "587a665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha <= 0: return x, y, torch.ones(len(x), device=x.device)\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    index = torch.randperm(x.size(0), device=x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, (y_a, y_b), lam\n",
    "\n",
    "def mixup_criterion(criterion, preds, target_pair, lam):\n",
    "    y_a, y_b = target_pair\n",
    "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9819fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_epoch_c10(loader, model, optimizer=None, scaler=None, use_mixup=False, alpha=0.2):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "    for imgs, targets in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            if is_train and use_mixup:\n",
    "                xm, tpair, lam = mixup_data(imgs, targets, alpha=alpha)\n",
    "                logits = model(xm)\n",
    "                loss = mixup_criterion(criterion_c10, logits, tpair, lam)\n",
    "                preds = logits.argmax(1)\n",
    "                hard_targets = targets  # for accuracy proxy\n",
    "            else:\n",
    "                logits = model(imgs)\n",
    "                loss = criterion_c10(logits, targets)\n",
    "                preds = logits.argmax(1)\n",
    "                hard_targets = targets\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct += (preds == hard_targets).sum().item()\n",
    "        total += imgs.size(0)\n",
    "\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_c10(loader, model):\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    all_preds, all_tgts = [], []\n",
    "    for imgs, targets in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion_c10(logits, targets)\n",
    "            preds = logits.argmax(1)\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += imgs.size(0)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_tgts.append(targets.cpu().numpy())\n",
    "\n",
    "    import numpy as np\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_tgts = np.concatenate(all_tgts)\n",
    "    return total_loss/total, correct/total, all_preds, all_tgts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97fe855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\2009227763.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]           C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\2009227763.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train 2.1363/0.1981 | Test 1.9411/0.2950 | lr 9.97e-04 | 258.1s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.2950)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train 1.7789/0.3276 | Test 1.6069/0.4045 | lr 9.89e-04 | 260.8s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.4045)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train 1.5637/0.4125 | Test 1.3541/0.4973 | lr 9.76e-04 | 254.3s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train 1.3984/0.4780 | Test 1.3561/0.4682 | lr 9.57e-04 | 255.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train 1.2869/0.5321 | Test 1.1245/0.5880 | lr 9.33e-04 | 258.3s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.5880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train 1.1892/0.5767 | Test 1.0761/0.6045 | lr 9.05e-04 | 248.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.6045)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train 1.0744/0.6226 | Test 0.9362/0.6720 | lr 8.72e-04 | 232.3s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.6720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train 1.0105/0.6466 | Test 0.9069/0.6775 | lr 8.35e-04 | 248.9s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.6775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train 0.9285/0.6749 | Test 0.8382/0.7150 | lr 7.94e-04 | 259.4s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train 0.8819/0.6892 | Test 0.8339/0.7140 | lr 7.50e-04 | 233.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train 0.8166/0.7157 | Test 0.7750/0.7312 | lr 7.03e-04 | 246.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train 0.7657/0.7368 | Test 0.7266/0.7570 | lr 6.55e-04 | 262.4s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7570)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train 0.6995/0.7561 | Test 0.7737/0.7395 | lr 6.04e-04 | 262.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train 0.6734/0.7659 | Test 0.6874/0.7665 | lr 5.52e-04 | 248.0s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7665)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train 0.6125/0.7870 | Test 0.6485/0.7770 | lr 5.00e-04 | 265.1s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train 0.5816/0.8004 | Test 0.6346/0.7893 | lr 4.48e-04 | 263.2s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7893)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train 0.5331/0.8184 | Test 0.6447/0.7895 | lr 3.96e-04 | 258.8s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.7895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train 0.4998/0.8240 | Test 0.6149/0.8010 | lr 3.45e-04 | 264.4s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train 0.4567/0.8424 | Test 0.5848/0.8113 | lr 2.97e-04 | 264.3s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train 0.4263/0.8524 | Test 0.6385/0.8020 | lr 2.50e-04 | 263.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train 0.3920/0.8666 | Test 0.5787/0.8207 | lr 2.06e-04 | 263.4s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train 0.3688/0.8721 | Test 0.5822/0.8153 | lr 1.65e-04 | 262.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train 0.3452/0.8806 | Test 0.5866/0.8225 | lr 1.28e-04 | 262.9s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train 0.3130/0.8920 | Test 0.5846/0.8220 | lr 9.55e-05 | 266.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train 0.2961/0.8977 | Test 0.5849/0.8250 | lr 6.70e-05 | 268.2s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train 0.2726/0.9071 | Test 0.5924/0.8287 | lr 4.32e-05 | 263.5s\n",
      "  ✔ Saved new best to checkpoints\\alexnet_cifar10.pt (test_acc=0.8287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train 0.2621/0.9081 | Test 0.6044/0.8247 | lr 2.45e-05 | 264.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train 0.2552/0.9114 | Test 0.6002/0.8285 | lr 1.09e-05 | 264.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train 0.2529/0.9135 | Test 0.5946/0.8283 | lr 2.74e-06 | 263.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train 0.2509/0.9115 | Test 0.5938/0.8270 | lr 0.00e+00 | 263.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_acc_c10 = 0.0\n",
    "best_path_c10 = os.path.join(CIFAR[\"save_dir\"], CIFAR[\"model_name\"])\n",
    "history_c10 = []\n",
    "\n",
    "for epoch in range(1, CIFAR[\"epochs\"]+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch_c10(\n",
    "        train_loader_c10,\n",
    "        alexnet_c10,\n",
    "        optimizer_c10,\n",
    "        scaler_c10,\n",
    "        use_mixup=CIFAR[\"use_mixup\"],\n",
    "        alpha=CIFAR[\"mixup_alpha\"]\n",
    "    )\n",
    "    te_loss, te_acc, _, _ = evaluate_c10(test_loader_c10, alexnet_c10)\n",
    "    scheduler_c10.step()\n",
    "\n",
    "    history_c10.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": tr_loss, \"train_acc\": tr_acc,\n",
    "        \"test_loss\": te_loss, \"test_acc\": te_acc,\n",
    "        \"lr\": scheduler_c10.get_last_lr()[0]\n",
    "    })\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train {tr_loss:.4f}/{tr_acc:.4f} | \"\n",
    "          f\"Test {te_loss:.4f}/{te_acc:.4f} | \"\n",
    "          f\"lr {scheduler_c10.get_last_lr()[0]:.2e} | {time.time()-t0:.1f}s\")\n",
    "\n",
    "    if te_acc > best_acc_c10:\n",
    "        best_acc_c10 = te_acc\n",
    "        torch.save({\n",
    "            \"model_state\": alexnet_c10.state_dict(),\n",
    "            \"classes\": cifar10_classes,\n",
    "            \"cfg\": CIFAR\n",
    "        }, best_path_c10)\n",
    "        print(f\"  ✔ Saved new best to {best_path_c10} (test_acc={best_acc_c10:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8d58e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]C:\\Users\\chuan\\AppData\\Local\\Temp\\ipykernel_34192\\2009227763.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best AlexNet CIFAR-10 test accuracy: 0.8287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane     0.8420    0.8125    0.8270       400\n",
      "  automobile     0.9295    0.9225    0.9260       400\n",
      "        bird     0.7291    0.7200    0.7245       400\n",
      "         cat     0.7216    0.7000    0.7107       400\n",
      "        deer     0.7694    0.8425    0.8043       400\n",
      "         dog     0.7881    0.7625    0.7751       400\n",
      "        frog     0.8453    0.9150    0.8788       400\n",
      "       horse     0.8770    0.8200    0.8475       400\n",
      "        ship     0.9015    0.9150    0.9082       400\n",
      "       truck     0.8864    0.8775    0.8819       400\n",
      "\n",
      "    accuracy                         0.8287      4000\n",
      "   macro avg     0.8290    0.8287    0.8284      4000\n",
      "weighted avg     0.8290    0.8287    0.8284      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[325,   7,  22,   5,   4,   0,   0,   8,  24,   5],\n",
       "       [  2, 369,   0,   2,   0,   0,   2,   0,   5,  20],\n",
       "       [ 16,   1, 288,  13,  30,  15,  25,   8,   1,   3],\n",
       "       [  3,   0,  17, 280,  21,  46,  19,   4,   5,   5],\n",
       "       [  3,   0,  22,  13, 337,   4,  13,   8,   0,   0],\n",
       "       [  1,   0,  16,  51,  12, 305,   2,  11,   0,   2],\n",
       "       [  2,   0,   9,   8,  11,   0, 366,   1,   1,   2],\n",
       "       [  4,   0,  14,   9,  22,  17,   2, 328,   0,   4],\n",
       "       [ 17,   2,   5,   2,   1,   0,   2,   1, 366,   4],\n",
       "       [ 13,  18,   2,   5,   0,   0,   2,   5,   4, 351]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "ckpt = torch.load(best_path_c10, map_location=device)\n",
    "alexnet_c10.load_state_dict(ckpt[\"model_state\"])\n",
    "\n",
    "test_loss, test_acc, preds, tgts = evaluate_c10(test_loader_c10, alexnet_c10)\n",
    "print(f\"\\nBest AlexNet CIFAR-10 test accuracy: {test_acc:.4f}\\n\")\n",
    "print(classification_report(tgts, preds, target_names=cifar10_classes, digits=4))\n",
    "\n",
    "cm = confusion_matrix(tgts, preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050644b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
